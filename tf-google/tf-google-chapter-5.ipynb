{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnist数据集：http://yann.lecun.com/exdb/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODE = 784 #输入层节点数，图片的像素\n",
    "\n",
    "OUTPUT_NODE = 10 #输出的类别数目\n",
    "\n",
    "LAYER1_NODE = 500 # 隐藏层节点数目\n",
    "\n",
    "BATCH_SIZE = 100 #一个训练batch中的训练数据个数\n",
    "\n",
    "LEARNING_RATE_BASE = 0.8 #基础的学习率\n",
    "\n",
    "LEARNING_RATE_DECAY = 0.99 #学习率的衰减率\n",
    "\n",
    "REGULARIZATION_RATE = 0.0001 #正则化项在损失函数中的系数\n",
    "\n",
    "TRAINING_STEPS = 5000 # 训练论数\n",
    "\n",
    "MOVING_AVERAGE_DECAY = 0.99 #滑动平均衰减率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义了使用relu的三层全连接神经网络的前向传播过程\n",
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class is None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1)\n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型的过程\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, INPUT_NODE], name=\"x-input\")\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, OUTPUT_NODE], name=\"y-input\")\n",
    "    \n",
    "    weight1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    \n",
    "    weight2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "        \n",
    "    #不使用滑动平均值\n",
    "    y = inference(x, None, weight1, biases1, weight2, biases2)\n",
    "    \n",
    "    #存储训练轮数的变量，不需要使用滑动平均值，所以trainable=False\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    #初始化滑动平均类\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    #对图上集合中没有指定trainable=False的参数应用滑动平均\n",
    "    variables_average_op = variable_averages.apply(tf.trainable_variables())\n",
    "    #使用滑动平均值\n",
    "    average_y = inference(x, variable_averages, weight1, biases1, weight2, biases2)\n",
    "    \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)\n",
    "    regularization = regularizer(weight1) + regularizer(weight2)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, #基础学习率\n",
    "                                               global_step, #当前迭代的轮数\n",
    "                                               mnist.train.num_examples/BATCH_SIZE, # 过完所有训练数据需要的迭代次数\n",
    "                                               LEARNING_RATE_DECAY,\n",
    "                                              staircase=True)  #学习率衰减速度\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "     # 反向传播更新参数和更新每一个参数的滑动平均值\n",
    "    with tf.control_dependencies([train_step, variables_average_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess.run(init_op)\n",
    "        #准备验证集\n",
    "        validata_feed = {x:mnist.validation.images, y_:mnist.validation.labels}\n",
    "        #准备测试集\n",
    "        test_feed = {x:mnist.test.images, y_:mnist.test.labels}\n",
    "        \n",
    "        #迭代训练神经网络\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i% 1000 == 0:\n",
    "                validata_acc = sess.run(accuracy, feed_dict=validata_feed)\n",
    "                print(\"after %d training step, validata accuracy is %g\" %(i, validata_acc))\n",
    "            xs, ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x:xs, y_:ys})\n",
    "        \n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"after %d training step, test accuracy is %g\" %(TRAINING_STEPS, test_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "after 0 training step, validata accuracy is 0.1118\n",
      "after 1000 training step, validata accuracy is 0.9784\n",
      "after 2000 training step, validata accuracy is 0.9828\n",
      "after 3000 training step, validata accuracy is 0.9836\n",
      "after 4000 training step, validata accuracy is 0.9854\n",
      "after 5000 training step, test accuracy is 0.9836\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"../data/MNIST_data\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v = tf.Variable(初始化值， 名字)\n",
    "v = tf.Variable(tf.constant(0.1, shape=[1]), name=\"v\")\n",
    "\n",
    "也可以使用tf.get_variable函数来创建或者获取变量\n",
    "v = tf.get_variable(\"v\", shape=[1], initializer=tf.constant_initializer(1.0))\n",
    "\n",
    "当tf.variable_scope 参数reuse=True生成上下文管理器时，\n",
    "tf.get_variable 获取已经创建的变量，如果变量不存在，报错；\n",
    "当tf.variable_scope 参数reuse=False 或者为None，\n",
    "tf.get_variable 如果变量已经存在，报错，否则创建新的变量；\n",
    "reuse默认是false\n",
    "\n",
    "在命名空间内创建的变量名称都会带上这个命名空间名作为前缀；\n",
    "\n",
    "可以直接通过带命名空间名称的变量名来获取其他命名空间下的变量；\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
